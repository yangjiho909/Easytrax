import requests
import json
import pandas as pd
from datetime import datetime, timedelta
import time
import re
from typing import Dict, List, Optional, Tuple
import logging
from dataclasses import dataclass
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import os

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TradeStatistics:
    """ìˆ˜ì¶œì… í†µê³„ ë°ì´í„° êµ¬ì¡°"""
    country: str
    hs_code: str
    period: str
    export_amount: float
    import_amount: float
    trade_balance: float
    issue_count: int
    major_issues: List[str]
    trend_summary: str
    data_points: List[Dict]
    created_at: str

class KOTRATradeStatisticsCrawler:
    """KOTRA ë¹…ë°ì´í„° ì‹œê°í™” ì‚¬ì´íŠ¸ ìˆ˜ì¶œì… í†µê³„ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.base_url = "https://www.kotra.or.kr/bigdata/bhrcMarket"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # ì§€ì› êµ­ê°€ ë° HS CODE ë§¤í•‘
        self.country_mapping = {
            "ì¤‘êµ­": "CN",
            "ë¯¸êµ­": "US"
        }
        
        # ì£¼ìš” HS CODE (ì‹í’ˆ ê´€ë ¨)
        self.common_hs_codes = {
            "ë¼ë©´": "190230",
            "ê³¼ì": "190531",
            "ìŒë£Œ": "220210",
            "ì¡°ë¯¸ë£Œ": "210390",
            "ê±´ì¡°ì‹í’ˆ": "071290"
        }
        
        # ìºì‹œ ë””ë ‰í† ë¦¬
        self.cache_dir = "trade_statistics_cache"
        os.makedirs(self.cache_dir, exist_ok=True)
        
        logger.info("âœ… KOTRA ìˆ˜ì¶œì… í†µê³„ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_trade_statistics(self, country: str, hs_code: str, period: str) -> Optional[TradeStatistics]:
        """íŠ¹ì • êµ­ê°€, HS CODE, ê¸°ê°„ì˜ ìˆ˜ì¶œì… í†µê³„ ì¡°íšŒ"""
        try:
            logger.info(f"ğŸ” {country} {hs_code} {period} ìˆ˜ì¶œì… í†µê³„ ì¡°íšŒ ì‹œì‘")
            
            # ìºì‹œ í™•ì¸
            cache_key = f"{country}_{hs_code}_{period}"
            cached_data = self._load_from_cache(cache_key)
            if cached_data:
                logger.info(f"âœ… ìºì‹œëœ ë°ì´í„° ì‚¬ìš©: {cache_key}")
                return cached_data
            
            # Seleniumì„ ì‚¬ìš©í•œ ë™ì  í¬ë¡¤ë§
            statistics = self._crawl_with_selenium(country, hs_code, period)
            
            if statistics:
                # ìºì‹œ ì €ì¥
                self._save_to_cache(cache_key, statistics)
                logger.info(f"âœ… {country} {hs_code} {period} í†µê³„ ì¡°íšŒ ì™„ë£Œ")
                return statistics
            else:
                logger.warning(f"âš ï¸ {country} {hs_code} {period} í†µê³„ ë°ì´í„° ì—†ìŒ")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ìˆ˜ì¶œì… í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _crawl_with_selenium(self, country: str, hs_code: str, period: str) -> Optional[TradeStatistics]:
        """Seleniumì„ ì‚¬ìš©í•œ ë™ì  í¬ë¡¤ë§"""
        driver = None
        try:
            # Chrome ì˜µì…˜ ì„¤ì •
            chrome_options = Options()
            chrome_options.add_argument("--headless")  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            
            driver = webdriver.Chrome(options=chrome_options)
            driver.get(self.base_url)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            wait = WebDriverWait(driver, 10)
            
            # êµ­ê°€ ì„ íƒ
            country_code = self.country_mapping.get(country)
            if not country_code:
                logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” êµ­ê°€: {country}")
                return None
            
            # HS CODE ì…ë ¥
            hs_input = wait.until(EC.presence_of_element_located((By.NAME, "hsCode")))
            hs_input.clear()
            hs_input.send_keys(hs_code)
            
            # ê¸°ê°„ ì„¤ì •
            period_data = self._parse_period(period)
            if period_data:
                start_date = driver.find_element(By.NAME, "startDate")
                end_date = driver.find_element(By.NAME, "endDate")
                start_date.clear()
                start_date.send_keys(period_data['start'])
                end_date.clear()
                end_date.send_keys(period_data['end'])
            
            # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
            search_button = driver.find_element(By.XPATH, "//button[contains(text(), 'ê²€ìƒ‰')]")
            search_button.click()
            
            # ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            time.sleep(3)
            
            # í†µê³„ ë°ì´í„° ì¶”ì¶œ
            statistics = self._extract_statistics_data(driver, country, hs_code, period)
            
            return statistics
            
        except TimeoutException:
            logger.error("âŒ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼")
            return None
        except Exception as e:
            logger.error(f"âŒ Selenium í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
        finally:
            if driver:
                driver.quit()
    
    def _extract_statistics_data(self, driver, country: str, hs_code: str, period: str) -> Optional[TradeStatistics]:
        """ì›¹í˜ì´ì§€ì—ì„œ í†µê³„ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # ìˆ˜ì¶œì… ê¸ˆì•¡ ì¶”ì¶œ
            export_amount = self._extract_amount(driver, "export")
            import_amount = self._extract_amount(driver, "import")
            trade_balance = export_amount - import_amount
            
            # ì£¼ìš” ì´ìŠˆ ì¶”ì¶œ
            major_issues = self._extract_major_issues(driver)
            issue_count = len(major_issues)
            
            # ì‹œê³„ì—´ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ì¶œ
            data_points = self._extract_time_series_data(driver)
            
            # íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±
            trend_summary = self._generate_trend_summary(data_points, export_amount, import_amount)
            
            statistics = TradeStatistics(
                country=country,
                hs_code=hs_code,
                period=period,
                export_amount=export_amount,
                import_amount=import_amount,
                trade_balance=trade_balance,
                issue_count=issue_count,
                major_issues=major_issues,
                trend_summary=trend_summary,
                data_points=data_points,
                created_at=datetime.now().isoformat()
            )
            
            return statistics
            
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _extract_amount(self, driver, trade_type: str) -> float:
        """ìˆ˜ì¶œ/ìˆ˜ì… ê¸ˆì•¡ ì¶”ì¶œ"""
        try:
            # ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì„ íƒì ìˆ˜ì • í•„ìš”
            if trade_type == "export":
                selector = "//div[contains(@class, 'export-amount')]//span[@class='value']"
            else:
                selector = "//div[contains(@class, 'import-amount')]//span[@class='value']"
            
            element = driver.find_element(By.XPATH, selector)
            amount_text = element.text.strip()
            
            # ìˆ«ìë§Œ ì¶”ì¶œ (ì½¤ë§ˆ, ì›í™” ê¸°í˜¸ ë“± ì œê±°)
            amount = re.sub(r'[^\d.]', '', amount_text)
            return float(amount) if amount else 0.0
            
        except NoSuchElementException:
            logger.warning(f"âš ï¸ {trade_type} ê¸ˆì•¡ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return 0.0
        except Exception as e:
            logger.error(f"âŒ {trade_type} ê¸ˆì•¡ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def _extract_major_issues(self, driver) -> List[str]:
        """ì£¼ìš” í†µê´€ ì´ìŠˆ ì¶”ì¶œ"""
        issues = []
        try:
            # ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì„ íƒì ìˆ˜ì • í•„ìš”
            issue_elements = driver.find_elements(By.XPATH, "//div[contains(@class, 'issue-item')]")
            
            for element in issue_elements[:5]:  # ìƒìœ„ 5ê°œ ì´ìŠˆë§Œ
                issue_text = element.text.strip()
                if issue_text:
                    issues.append(issue_text)
            
        except Exception as e:
            logger.error(f"âŒ ì£¼ìš” ì´ìŠˆ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return issues
    
    def _extract_time_series_data(self, driver) -> List[Dict]:
        """ì‹œê³„ì—´ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ì¶œ"""
        data_points = []
        try:
            # ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì„ íƒì ìˆ˜ì • í•„ìš”
            chart_elements = driver.find_elements(By.XPATH, "//div[contains(@class, 'chart-data-point')]")
            
            for element in chart_elements:
                try:
                    date = element.get_attribute("data-date")
                    export_val = element.get_attribute("data-export")
                    import_val = element.get_attribute("data-import")
                    
                    if date and export_val and import_val:
                        data_points.append({
                            "date": date,
                            "export": float(export_val),
                            "import": float(import_val),
                            "balance": float(export_val) - float(import_val)
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ë°ì´í„° í¬ì¸íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                    continue
            
        except Exception as e:
            logger.error(f"âŒ ì‹œê³„ì—´ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return data_points
    
    def _generate_trend_summary(self, data_points: List[Dict], export_amount: float, import_amount: float) -> str:
        """íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±"""
        if not data_points:
            return "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ ë¶ˆê°€"
        
        try:
            # ìµœê·¼ 3ê°œì›” ë°ì´í„°ë¡œ íŠ¸ë Œë“œ ë¶„ì„
            recent_data = data_points[-3:] if len(data_points) >= 3 else data_points
            
            export_trend = "ì¦ê°€" if recent_data[-1]["export"] > recent_data[0]["export"] else "ê°ì†Œ"
            import_trend = "ì¦ê°€" if recent_data[-1]["import"] > recent_data[0]["import"] else "ê°ì†Œ"
            
            balance_trend = "í‘ì" if export_amount > import_amount else "ì ì"
            
            summary = f"ìˆ˜ì¶œì€ {export_trend} ì¶”ì„¸, ìˆ˜ì…ì€ {import_trend} ì¶”ì„¸ì´ë©°, {balance_trend} ìƒíƒœì…ë‹ˆë‹¤."
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ íŠ¸ë Œë“œ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return "íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
    
    def _parse_period(self, period: str) -> Optional[Dict]:
        """ê¸°ê°„ ë¬¸ìì—´ íŒŒì‹±"""
        try:
            # "2025ë…„ 1ë¶„ê¸°" í˜•ì‹ íŒŒì‹±
            year_match = re.search(r'(\d{4})ë…„', period)
            quarter_match = re.search(r'(\d+)ë¶„ê¸°', period)
            
            if year_match and quarter_match:
                year = int(year_match.group(1))
                quarter = int(quarter_match.group(1))
                
                # ë¶„ê¸°ë³„ ì‹œì‘/ì¢…ë£Œ ì›” ê³„ì‚°
                start_month = (quarter - 1) * 3 + 1
                end_month = quarter * 3
                
                start_date = f"{year:04d}-{start_month:02d}-01"
                end_date = f"{year:04d}-{end_month:02d}-28"  # ê°„ë‹¨íˆ 28ì¼ë¡œ ì„¤ì •
                
                return {
                    "start": start_date,
                    "end": end_date
                }
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ê°„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _save_to_cache(self, key: str, data: TradeStatistics):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{key}.json")
            
            # dataclassë¥¼ dictë¡œ ë³€í™˜
            cache_data = {
                "country": data.country,
                "hs_code": data.hs_code,
                "period": data.period,
                "export_amount": data.export_amount,
                "import_amount": data.import_amount,
                "trade_balance": data.trade_balance,
                "issue_count": data.issue_count,
                "major_issues": data.major_issues,
                "trend_summary": data.trend_summary,
                "data_points": data.data_points,
                "created_at": data.created_at
            }
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_file}")
            
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def _load_from_cache(self, key: str) -> Optional[TradeStatistics]:
        """ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{key}.json")
            
            if not os.path.exists(cache_file):
                return None
            
            # ìºì‹œ ë§Œë£Œ í™•ì¸ (24ì‹œê°„)
            file_time = os.path.getmtime(cache_file)
            if time.time() - file_time > 86400:  # 24ì‹œê°„
                logger.info(f"ğŸ”„ ìºì‹œ ë§Œë£Œ: {cache_file}")
                return None
            
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # dictë¥¼ dataclassë¡œ ë³€í™˜
            statistics = TradeStatistics(
                country=cache_data["country"],
                hs_code=cache_data["hs_code"],
                period=cache_data["period"],
                export_amount=cache_data["export_amount"],
                import_amount=cache_data["import_amount"],
                trade_balance=cache_data["trade_balance"],
                issue_count=cache_data["issue_count"],
                major_issues=cache_data["major_issues"],
                trend_summary=cache_data["trend_summary"],
                data_points=cache_data["data_points"],
                created_at=cache_data["created_at"]
            )
            
            logger.info(f"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {cache_file}")
            return statistics
            
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def generate_db_table_data(self, statistics: TradeStatistics) -> Dict:
        """DB ì ì¬ìš© í…Œì´ë¸” í˜•íƒœ ë°ì´í„° ìƒì„±"""
        try:
            db_data = {
                "table_name": "trade_statistics",
                "columns": [
                    "country", "hs_code", "period", "export_amount", 
                    "import_amount", "trade_balance", "issue_count",
                    "major_issues", "trend_summary", "created_at"
                ],
                "data": [
                    {
                        "country": statistics.country,
                        "hs_code": statistics.hs_code,
                        "period": statistics.period,
                        "export_amount": statistics.export_amount,
                        "import_amount": statistics.import_amount,
                        "trade_balance": statistics.trade_balance,
                        "issue_count": statistics.issue_count,
                        "major_issues": json.dumps(statistics.major_issues, ensure_ascii=False),
                        "trend_summary": statistics.trend_summary,
                        "created_at": statistics.created_at
                    }
                ],
                "time_series_table": {
                    "table_name": "trade_statistics_time_series",
                    "columns": ["country", "hs_code", "period", "date", "export", "import", "balance"],
                    "data": [
                        {
                            "country": statistics.country,
                            "hs_code": statistics.hs_code,
                            "period": statistics.period,
                            "date": point["date"],
                            "export": point["export"],
                            "import": point["import"],
                            "balance": point["balance"]
                        }
                        for point in statistics.data_points
                    ]
                }
            }
            
            return db_data
            
        except Exception as e:
            logger.error(f"âŒ DB í…Œì´ë¸” ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def generate_visualization_data(self, statistics: TradeStatistics) -> Dict:
        """ì‹œê°í™”ìš© ê·¸ë˜í”„ ë°ì´í„° ìƒì„±"""
        try:
            viz_data = {
                "summary": {
                    "export_amount": statistics.export_amount,
                    "import_amount": statistics.import_amount,
                    "trade_balance": statistics.trade_balance,
                    "issue_count": statistics.issue_count
                },
                "trend_summary": statistics.trend_summary,
                "time_series": {
                    "labels": [point["date"] for point in statistics.data_points],
                    "export_data": [point["export"] for point in statistics.data_points],
                    "import_data": [point["import"] for point in statistics.data_points],
                    "balance_data": [point["balance"] for point in statistics.data_points]
                },
                "major_issues": statistics.major_issues
            }
            
            return viz_data
            
        except Exception as e:
            logger.error(f"âŒ ì‹œê°í™” ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def get_api_status(self) -> Dict:
        """API ìƒíƒœ í™•ì¸"""
        return {
            "service_available": True,
            "supported_countries": list(self.country_mapping.keys()),
            "common_hs_codes": self.common_hs_codes,
            "cache_directory": self.cache_dir,
            "last_update": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "api_connection": "initialized"
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    crawler = KOTRATradeStatisticsCrawler()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    statistics = crawler.get_trade_statistics("ì¤‘êµ­", "190230", "2025ë…„ 1ë¶„ê¸°")
    
    if statistics:
        print(f"âœ… í†µê³„ ì¡°íšŒ ì„±ê³µ: {statistics.country} {statistics.hs_code}")
        print(f"ìˆ˜ì¶œì•¡: {statistics.export_amount:,.0f}")
        print(f"ìˆ˜ì…ì•¡: {statistics.import_amount:,.0f}")
        print(f"ë¬´ì—­ìˆ˜ì§€: {statistics.trade_balance:,.0f}")
        print(f"ì£¼ìš” ì´ìŠˆ: {len(statistics.major_issues)}ê°œ")
        print(f"íŠ¸ë Œë“œ: {statistics.trend_summary}")
        
        # DB í…Œì´ë¸” ë°ì´í„° ìƒì„±
        db_data = crawler.generate_db_table_data(statistics)
        print(f"DB í…Œì´ë¸” ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(db_data.get('data', []))}ê°œ í–‰")
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        viz_data = crawler.generate_visualization_data(statistics)
        print(f"ì‹œê°í™” ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(viz_data.get('time_series', {}).get('labels', []))}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
    else:
        print("âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨") 