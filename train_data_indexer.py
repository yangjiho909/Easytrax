import os
import pandas as pd
import pickle
from glob import glob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")
from soynlp.tokenizer import RegexTokenizer
warnings.filterwarnings("ignore", category=FutureWarning, module="soynlp")
tokenizer = RegexTokenizer()

def tokenize(text):
    return tokenizer.tokenize(text, flatten=True)

# ğŸ“ ë°ì´í„° í´ë” ê²½ë¡œ
data_dir = "data"

# ğŸ” data/ í´ë” ë‚´ ëª¨ë“  .xlsx íŒŒì¼ ê²€ìƒ‰
excel_files = glob(os.path.join(data_dir, "customsExcel*.xlsx"))
all_dataframes = []

for file in excel_files:
    try:
        df = pd.read_excel(file)

        # âœ… ë¬¸ì œì‚¬ìœ  ë³‘í•© ì²˜ë¦¬
        sa_yu_cols = [col for col in df.columns if "ë¬¸ì œì‚¬ìœ " in col]
        df["ë¬¸ì œì‚¬ìœ "] = df[sa_yu_cols].fillna("").astype(str).agg(" ".join, axis=1)

        # âœ… ì£¼ìš” ì—´ í•„í„°ë§ ë° ì •ë¦¬
        df = df[["í’ˆëª©", "ì›ì‚°ì§€", "ìˆ˜ì…êµ­", "ì¡°ì¹˜ì‚¬í•­", "ë¬¸ì œì‚¬ìœ ", "HS CODE"]].dropna()
        df["ì¶œì²˜íŒŒì¼"] = os.path.basename(file)

        all_dataframes.append(df)
        print(f"[âœ“] Loaded: {os.path.basename(file)}")
    except Exception as e:
        print(f"[!] Failed to load {file}: {e}")

# ğŸ”— ëª¨ë“  ë°ì´í„° í•©ì¹˜ê¸°
if all_dataframes:
    full_df = pd.concat(all_dataframes, ignore_index=True)
    print(f"âœ… ì´ ë°ì´í„° ìˆ˜: {len(full_df)}")

else:
    raise ValueError("âŒ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")



# í…ìŠ¤íŠ¸ ê²°í•©: í’ˆëª© + ì›ì‚°ì§€ + ìˆ˜ì…êµ­ + ë¬¸ì œì‚¬ìœ 
full_df["í…ìŠ¤íŠ¸"] = (
    full_df["í’ˆëª©"].astype(str) + " " +
    full_df["ì›ì‚°ì§€"].astype(str) + " " +
    full_df["ìˆ˜ì…êµ­"].astype(str) + " " +
    full_df["ë¬¸ì œì‚¬ìœ "].astype(str) + " " +
    full_df["HS CODE"].astype(str)
)

# í† í°í™” ì ìš©
full_df["í…ìŠ¤íŠ¸"] = full_df["í…ìŠ¤íŠ¸"].apply(lambda x: " ".join(tokenize(x)))

# TF-IDF ë²¡í„°í™”
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(full_df["í…ìŠ¤íŠ¸"])

os.makedirs("model", exist_ok=True)
with open("model/vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)
with open("model/indexed_matrix.pkl", "wb") as f:
    pickle.dump(X, f)
with open("model/raw_data.pkl", "wb") as f:
    pickle.dump(full_df, f)

print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ (model/ í´ë”)")
