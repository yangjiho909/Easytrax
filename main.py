import warnings
import pickle
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from soynlp.tokenizer import RegexTokenizer
warnings.filterwarnings("ignore", category=FutureWarning, module="soynlp")

pd.set_option("display.max_colwidth", None)     # ê° ì…€ ë‚´ìš© ì „ë¶€ ì¶œë ¥
pd.set_option("display.max_columns", None)      # ëª¨ë“  ì—´ ì¶œë ¥
pd.set_option("display.width", 300)            # ì „ì²´ ì¤„ í­ ì§€ì •


tokenizer = RegexTokenizer()

def tokenize(text):
    return tokenizer.tokenize(text, flatten=True)  # ë‹¨ì–´ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

def visualize_statistics(cases):
    df = pd.DataFrame(cases)
    
    if df.empty:
        print("âš ï¸ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ“Š ìœ ì‚¬ ì‚¬ë¡€ í†µê³„ ìš”ì•½:")
    print("=" * 40)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë“¤ í™•ì¸
    available_columns = list(df.columns)
    print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì •ë³´: {available_columns}")
    
    # âœ… 1. ì¡°ì¹˜ì‚¬í•­ ë¶„í¬ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ê³  "ì •ë³´ ì—†ìŒ"ì´ ì•„ë‹ ë•Œë§Œ)
    if "ì¡°ì¹˜ì‚¬í•­" in df.columns:
        action_counts = df["ì¡°ì¹˜ì‚¬í•­"].value_counts()
        valid_actions = action_counts[action_counts.index != "ì •ë³´ ì—†ìŒ"]
        
        if not valid_actions.empty:
            print(f"\nğŸ› ï¸ ì¡°ì¹˜ì‚¬í•­ ë¶„í¬:")
            for action, count in valid_actions.head(5).items():
                print(f"   - {action}: {count}ê±´")
        else:
            print("\nâš ï¸ ì¡°ì¹˜ì‚¬í•­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ì¡°ì¹˜ì‚¬í•­ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # âœ… 2. í’ˆëª© ìƒìœ„ 5ê°œ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ê³  "ì •ë³´ ì—†ìŒ"ì´ ì•„ë‹ ë•Œë§Œ)
    if "í’ˆëª©" in df.columns:
        item_counts = df["í’ˆëª©"].value_counts()
        valid_items = item_counts[item_counts.index != "ì •ë³´ ì—†ìŒ"]
        
        if not valid_items.empty:
            print(f"\nğŸ“¦ ì£¼ìš” í’ˆëª©:")
            for item, count in valid_items.head(5).items():
                print(f"   - {item}: {count}ê±´")
        else:
            print("\nâš ï¸ í’ˆëª© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ í’ˆëª© ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # âœ… 3. ìˆ˜ì…êµ­ ë¶„í¬
    if "ìˆ˜ì…êµ­" in df.columns:
        country_counts = df["ìˆ˜ì…êµ­"].value_counts()
        valid_countries = country_counts[country_counts.index != "ì •ë³´ ì—†ìŒ"]
        
        if not valid_countries.empty:
            print(f"\nğŸŒ ì£¼ìš” ìˆ˜ì…êµ­:")
            for country, count in valid_countries.head(5).items():
                print(f"   - {country}: {count}ê±´")
        else:
            print("\nâš ï¸ ìˆ˜ì…êµ­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ìˆ˜ì…êµ­ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")




# -----------------------------
# ëª¨ë¸ ë¡œë“œ
# -----------------------------
def load_model():
    with open("model/vectorizer.pkl", "rb") as f:
        vectorizer = pickle.load(f)
    with open("model/indexed_matrix.pkl", "rb") as f:
        tfidf_matrix = pickle.load(f)
    with open("model/raw_data.pkl", "rb") as f:
        raw_data = pickle.load(f)
    return vectorizer, tfidf_matrix, raw_data

# -----------------------------
# ìœ ì‚¬ë„ ë¶„ì„
# -----------------------------
def analyze_input(user_input, vectorizer, tfidf_matrix, raw_data, top_k=15, threshold=0.1):
    input_vec = vectorizer.transform([user_input])
    similarities = cosine_similarity(input_vec, tfidf_matrix).flatten()
    top_indices = similarities.argsort()[::-1]

    results = []
    for idx in top_indices:
        sim = similarities[idx]
        if sim < threshold:
            break  # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì¤‘ë‹¨
        row = raw_data.iloc[idx]
        result = {
            "í’ˆëª©": row.get("í’ˆëª©", "ì •ë³´ ì—†ìŒ"),
            "ì›ì‚°ì§€": row.get("ì›ì‚°ì§€", "ì •ë³´ ì—†ìŒ"),
            "ìˆ˜ì…êµ­": row.get("ìˆ˜ì…êµ­", "ì •ë³´ ì—†ìŒ"),
            "ì¡°ì¹˜ì‚¬í•­": row.get("ì¡°ì¹˜ì‚¬í•­", "ì •ë³´ ì—†ìŒ"),
            "ë¬¸ì œì‚¬ìœ ": row.get("ë¬¸ì œì‚¬ìœ ", "ì •ë³´ ì—†ìŒ"),
            "ì¶œì²˜íŒŒì¼": row.get("ì¶œì²˜íŒŒì¼", "ì •ë³´ ì—†ìŒ"),
            "HS CODE": row.get("HS CODE", "ì •ë³´ ì—†ìŒ"),
            "ìœ ì‚¬ë„": round(float(sim), 3)
        }
        results.append(result)
        if len(results) >= top_k:
            break

    return results


# -----------------------------
# ê°œì„  ì œì•ˆ ìƒì„±
# -----------------------------
def suggest_improvement(cases):
    reasons = " ".join([case["ë¬¸ì œì‚¬ìœ "] for case in cases]).lower()
    suggestions = []

    if "ì„œë¥˜" in reasons or "ì¸ì¦" in reasons:
        suggestions.append("- ê´€ë ¨ ì¸ì¦ì„œë¥˜ ë° ì‹œí—˜ì„±ì ì„œë¥¼ ì²¨ë¶€í•˜ì‹­ì‹œì˜¤.")
    if "ë¼ë²¨" in reasons or "í‘œì‹œ" in reasons:
        suggestions.append("- ì œí’ˆ ë¼ë²¨ì— ì›ì‚°ì§€, ìˆ˜ì¶œì, ì„±ë¶„ ì •ë³´ë¥¼ ëª…í™•íˆ í‘œê¸°í•˜ì‹­ì‹œì˜¤.")
    if "ì„±ë¶„" in reasons or "ì²¨ê°€ë¬¼" in reasons:
        suggestions.append("- ì‹í’ˆì²¨ê°€ë¬¼ ë° ìœ í•´ë¬¼ì§ˆì˜ í•¨ëŸ‰ ê¸°ì¤€ì„ í™•ì¸í•˜ê³  ì¡°ì •í•˜ì‹­ì‹œì˜¤.")
    if "ê²€ì—­" in reasons or "í•´ì¶©" in reasons:
        suggestions.append("- ë°©ì—­/ê²€ì—­ ê´€ë ¨ ì‚¬ì „ ì ê²€ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤.")
    if not suggestions:
        suggestions.append("- ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì •ë³´ë¥¼ ì‹ ì¤‘íˆ ì ê²€í•˜ì‹­ì‹œì˜¤.")
    return suggestions

# -----------------------------
# ë©”ì¸ ë¡œì§
# -----------------------------
def main():
    print("âœ… ìˆ˜ì¶œí•˜ê³ ì í•˜ëŠ” ì œí’ˆ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    user_input = input("ì œí’ˆ ì„¤ëª…: ")

    vectorizer, tfidf_matrix, raw_data = load_model()
    
    user_input = " ".join(tokenize(user_input))
    

    top_cases = analyze_input(user_input, vectorizer, tfidf_matrix, raw_data, top_k=15, threshold=0.1)

    print("\nğŸ“Œ ìœ ì‚¬ í†µê´€ ì‹¤íŒ¨ ì‚¬ë¡€:")
    df = pd.DataFrame(top_cases)
    for i, row in df.iterrows():
        print(f"\nğŸ§¾ [ì‚¬ë¡€ {i+1}]")
        print(f"í’ˆëª©     : {row.get('í’ˆëª©', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì›ì‚°ì§€   : {row.get('ì›ì‚°ì§€', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ìˆ˜ì…êµ­   : {row.get('ìˆ˜ì…êµ­', 'ì •ë³´ ì—†ìŒ')}")
        print(f"ì¡°ì¹˜ì‚¬í•­ : {row.get('ì¡°ì¹˜ì‚¬í•­', 'ì •ë³´ ì—†ìŒ')}")
        ë¬¸ì œì‚¬ìœ  = row.get("ë¬¸ì œì‚¬ìœ ", "ì •ë³´ ì—†ìŒ")
        # ì„¸ë¡œ ì¤„ë°”ê¿ˆ ì ìš© (ì„ì˜ ê¸°ì¤€ìœ¼ë¡œ)
        if isinstance(ë¬¸ì œì‚¬ìœ , str) and len(ë¬¸ì œì‚¬ìœ ) > 50:
            print("ë¬¸ì œì‚¬ìœ  :")
            for chunk in [ë¬¸ì œì‚¬ìœ [i:i+50] for i in range(0, len(ë¬¸ì œì‚¬ìœ ), 50)]:
                print("          " + chunk)
        else:
            print(f"ë¬¸ì œì‚¬ìœ  : {ë¬¸ì œì‚¬ìœ }")
        print(f"ìœ ì‚¬ë„   : {row.get('ìœ ì‚¬ë„', 0):.3f}")
        hscode = row.get("HS CODE", "ì •ë³´ ì—†ìŒ")
        if isinstance(hscode, float):
            if hscode.is_integer():
                hscode = str(int(hscode))
            else:
                hscode = str(hscode)
        print(f"HS CODE : {hscode}")


    print("\nğŸ› ï¸ ê°œì„  ì œì•ˆ:")
    for s in suggest_improvement(top_cases):
        print(s)

    # ì‹œê°í™” ì‹¤í–‰
    print("\nğŸ“Š ìœ ì‚¬ ì‚¬ë¡€ í†µê³„ ìš”ì•½:")
    visualize_statistics(top_cases)

    print("\nğŸ” ìœ„ ì‚¬ë¡€ë“¤ì„ ì°¸ê³ í•˜ì—¬ í†µê´€ ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”í•˜ì„¸ìš”.")


# -----------------------------
# ì‹¤í–‰
# -----------------------------
if __name__ == "__main__":
    from main import main
    main()  # ì‚¬ìš©ì ì…ë ¥ ë°˜ë³µ
