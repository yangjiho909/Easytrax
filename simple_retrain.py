#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import pickle
from glob import glob
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import warnings
warnings.filterwarnings("ignore")

def train_and_save_model(data_dir="data", model_dir="model"):
    print("ğŸ§¼ í†µê´€ ì‹¤íŒ¨ ë°ì´í„° ì •ì œ ë° ëª¨ë¸ ì¬í•™ìŠµ...")
    excel_files = glob(os.path.join(data_dir, "*.xlsx"))
    
    if not excel_files:
        print("âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“ ë°œê²¬ëœ ì—‘ì…€ íŒŒì¼: {len(excel_files)}ê°œ")
    all_df = []

    for i, file in enumerate(excel_files):
        print(f"ğŸ“Š ì²˜ë¦¬ ì¤‘: {os.path.basename(file)}")
        try:
            df = pd.read_excel(file)
            print(f"   - í–‰ ìˆ˜: {len(df)}")
            print(f"   - ì»¬ëŸ¼: {list(df.columns)}")
            
            # ë¬¸ì œì‚¬ìœ  ì»¬ëŸ¼ ì°¾ê¸°
            sa_yu_cols = [col for col in df.columns if "ë¬¸ì œì‚¬ìœ " in col or "ì‚¬ìœ " in col]
            if sa_yu_cols:
                df["ë¬¸ì œì‚¬ìœ "] = df[sa_yu_cols].fillna("").astype(str).agg(" ".join, axis=1)
            else:
                df["ë¬¸ì œì‚¬ìœ "] = "ì •ë³´ ì—†ìŒ"
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ í™•ì¸
            required_cols = ["í’ˆëª©", "ì›ì‚°ì§€", "ìˆ˜ì…êµ­", "ì¡°ì¹˜ì‚¬í•­"]
            available_cols = [col for col in required_cols if col in df.columns]
            
            if len(available_cols) >= 3:  # ìµœì†Œ 3ê°œ ì»¬ëŸ¼ì€ ìˆì–´ì•¼ í•¨
                df = df[available_cols + ["ë¬¸ì œì‚¬ìœ "]].dropna()
                df["ì¶œì²˜íŒŒì¼"] = os.path.basename(file)
                all_df.append(df)
                print(f"   âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(df)}í–‰")
            else:
                print(f"   âš ï¸ í•„ìš”í•œ ì»¬ëŸ¼ ë¶€ì¡±. ì‚¬ìš© ê°€ëŠ¥: {available_cols}")
                
        except Exception as e:
            print(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    if not all_df:
        print("âŒ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    full_df = pd.concat(all_df, ignore_index=True)
    print(f"\nâœ… ì´ {len(full_df)}ê°œì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    
    # í•œêµ­ ê´€ë ¨ ë°ì´í„° í™•ì¸
    korean_data = full_df[full_df["ì›ì‚°ì§€"].str.contains("í•œêµ­|ëŒ€í•œë¯¼êµ­", na=False)]
    print(f"ğŸ‡°ğŸ‡· í•œêµ­ ì›ì‚°ì§€ ë°ì´í„°: {len(korean_data)}ê±´ ({len(korean_data)/len(full_df)*100:.1f}%)")
    
    if len(korean_data) > 0:
        print(f"   - ì£¼ìš” ìˆ˜ì…êµ­: {list(korean_data['ìˆ˜ì…êµ­'].value_counts().head(5).index)}")
        print(f"   - ì£¼ìš” í’ˆëª©: {list(korean_data['í’ˆëª©'].value_counts().head(5).index)}")
    
    # í…ìŠ¤íŠ¸ ê²°í•©
    text_cols = [col for col in ["í’ˆëª©", "ì›ì‚°ì§€", "ìˆ˜ì…êµ­", "ë¬¸ì œì‚¬ìœ "] if col in full_df.columns]
    full_df["í…ìŠ¤íŠ¸"] = full_df[text_cols].astype(str).agg(" ".join, axis=1)

    # TF-IDF ë²¡í„°í™”
    print("ğŸ”§ TF-IDF ë²¡í„°í™” ì¤‘...")
    vectorizer = TfidfVectorizer(max_features=5000, stop_words=None)
    X = vectorizer.fit_transform(full_df["í…ìŠ¤íŠ¸"])

    # ëª¨ë¸ ì €ì¥
    os.makedirs(model_dir, exist_ok=True)
    with open(os.path.join(model_dir, "vectorizer.pkl"), "wb") as f:
        pickle.dump(vectorizer, f)
    with open(os.path.join(model_dir, "indexed_matrix.pkl"), "wb") as f:
        pickle.dump(X, f)
    with open(os.path.join(model_dir, "raw_data.pkl"), "wb") as f:
        pickle.dump(full_df, f)

    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {model_dir}/")
    print(f"ğŸ“Š ìµœì¢… ë°ì´í„° ìˆ˜: {len(full_df)}ê±´")

if __name__ == "__main__":
    train_and_save_model() 